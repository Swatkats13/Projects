{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKskpXFuFTCT"
   },
   "source": [
    "# Goal: Full Fine-tuning BERT\n",
    "\n",
    "In this project, we will create a **BERT-based text classifier** (actually **DistilBERT**) using the [Hugging Face Transformers](https://huggingface.co/transformers/) library. We will perform **full fine-tuning** on the **SMS Spam dataset** from the [datasets](https://huggingface.co/docs/datasets/) package and evaluate our modelâ€™s performance.\n",
    "\n",
    "The **SMS Spam dataset (sms_spam)** contains text messages that are **labeled as either 'ham' (not spam) or 'spam'**, making it a **binary classification problem**. Our goal is to fine-tune a DistilBERT model to accurately classify these messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312,
     "referenced_widgets": [
      "f6786a979dc34bca978c792c1fd9bd75",
      "1495800c00f346e29de43ff7074430fa",
      "3ed11002fc624b8a8947d8d4b13dc467",
      "88e85ce3a12c4b3c97a5c63c49e0bd53",
      "689cd7ff315b426c9574d82e48d9f6ce",
      "0591b1d9912444adbd2cf4b44151c2e6",
      "5d28ef7cc6214e76843d77e6511ba630",
      "7f39145ebaeb44aa923320afa9e5023c",
      "3c058e62bc704bb0aa681b2d6987c76d",
      "78e9b7ea91e6420ebeb118358a487354",
      "1da9b0aecb474a519b802cf66e4a7ae3",
      "bc53c4edbe8f4c1c9c7b840857dcfbb2",
      "b824b01b768b41b68dc05df98c032406",
      "33ca5f93b0e34797865c085abe2e5bdb",
      "42d53ae86be64f668ef207bced4a0946",
      "baf530be944c480bab8b37c43bd1ae08",
      "81b272c2e6444aa5bcc527324469b427",
      "18e1c2c251044baba4a37bf9060c9886",
      "ead27e55dd0948e3a90cc3531478f418",
      "386ad3809ed6428aa87460a536ca366c",
      "cca12862f1c74a7ca151224e3a269925",
      "407df08599c54ceaab7ea70f5353cc8a",
      "a80993feec0f42a1a40ee7a7b2b0a587",
      "917b1532152d46c98780113cdf28fb4c",
      "e4c8a29a682349cc82fe6689438ad216",
      "3e90375f922c4afcbc48e55b68d70678",
      "cb1f0cd4beb04bf8baa44120a9609865",
      "1f68f87876c542dea3266797b9c56e6b",
      "16173087e24d4f6eaffd9d1c6c2cf327",
      "29ca41b54dbf415fa3daea8bb45f76b9",
      "0233aed625e747f1a3c9ddf8492ace76",
      "05423c274d404419aee99dded780a84e",
      "ea8d7c4d3fad497f8fd7599c0fa7bdaf"
     ]
    },
    "executionInfo": {
     "elapsed": 5087,
     "status": "ok",
     "timestamp": 1753476073238,
     "user": {
      "displayName": "Srishti Jain",
      "userId": "17735186882349502119"
     },
     "user_tz": 240
    },
    "id": "y3cHpILUFTCV",
    "outputId": "5f473b79-f5b6-4a08-9674-352650c88df5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6786a979dc34bca978c792c1fd9bd75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc53c4edbe8f4c1c9c7b840857dcfbb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/359k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a80993feec0f42a1a40ee7a7b2b0a587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5574 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sms', 'label'],\n",
       "    num_rows: 4459\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the sms_spam dataset\n",
    "# See: https://huggingface.co/datasets/sms_spam\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# The sms_spam dataset only has a train split, so we use the train_test_split method to split it into train and test\n",
    "dataset = load_dataset(\"sms_spam\", split=\"train\").train_test_split(\n",
    "    test_size=0.2, shuffle=True, seed=23\n",
    ")\n",
    "\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "# View the dataset characteristics\n",
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLlleQ9UFTCW"
   },
   "source": [
    "Let's look at the first example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1753476096232,
     "user": {
      "displayName": "Srishti Jain",
      "userId": "17735186882349502119"
     },
     "user_tz": 240
    },
    "id": "_pQqmVUsFTCX",
    "outputId": "33da5724-587a-4231-8198-3e78ead12ed9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sms': 'Had your mobile 10 mths? Update to the latest Camera/Video phones for FREE. KEEP UR SAME NUMBER, Get extra free mins/texts. Text YES for a call\\n',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the first example. Do you think this is spam or not?\n",
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfzEZFUdFTCX"
   },
   "source": [
    "## Pre-process datasets\n",
    "\n",
    "Now we are going to process our datasets by converting all the text into tokens for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280,
     "referenced_widgets": [
      "f409523dfa724375898d702f6e01daec",
      "0706ad45a5e14056bf77d7fc42822a2a",
      "ca86f9775eb54dd39db0fffc11ee45df",
      "f20ed57e71e9483e995b0210ee8ba240",
      "ea26785f54534abbad7c542ec91a187e",
      "fa1cee0a65374da9bc2edea2cb8f34bd",
      "7762652f8000431aa138103ec504b76f",
      "86499b7c38fe45dc8f34f7e0ada53eb6",
      "ba447489434943689f4691ff57d8925c",
      "db06e52a9d574c58b760b3c5a4503deb",
      "ccc44de9f8b542cfb069e5600c9512ed",
      "f02cdf6fd55a445f9b66cddbd92b3559",
      "75ff32cea2c4480ba39af88415910424",
      "c33bf749ace440d3ac1fb75edc5a739d",
      "4fa2720c97aa47d8bd9e685bca37bbdb",
      "457fad533cb642919127862151532842",
      "e7b88e466f25424eb5cc24ed1d478708",
      "6dea427d36a841359e2bacc017df83a4",
      "2beeacbb433748ca9f18c9c2db69711f",
      "8128a7bb3d8842b29927867d7d84007e",
      "3ec41e3ae5ed47ee81fb7065424b1c3c",
      "cbc228d0a80f4b2bb7741e467c33df43",
      "b2937f86e111457cb2e11383edd6266e",
      "5f1f1e26f5f744919daed8ede5ce43bd",
      "e14f6d280fb64994b56d2391ddeade56",
      "6f54900bc06540a7a6f9cb87af0feb14",
      "a2ecc7855a894f23aeb92048c33accda",
      "1cb1b78344ad49baafdcdfe8ab6242b0",
      "d2288c88747f4cd8a0924fb521e39738",
      "c75e4066ab9343b3ad0677d6fbef5376",
      "a2ad26f7d47841feaeadbf5dccfb3231",
      "dd0564b7f16a46358308bec5267e7813",
      "d1b3f4eab48a4f3cbf5c2338e171571f",
      "c7ebc5f92f1140cebfba161f2d3f1ade",
      "8a5631eaf4d84108b4b5f8a4ef84b0e5",
      "cb333b66979f43248be2958266377d6e",
      "ee0231f1f4ab460699bc662fb23dfddb",
      "6e49d20626684aa2af55e153b232ccb0",
      "a8af7dd7a5ce4104954cd1af9d34c516",
      "257778665eca4468a016cd4e1cbddbb5",
      "d399415403c64671a4925593b6119db0",
      "71c00add813e4d2fae69e080aa7c4df2",
      "fd21aed7e0fd4d439f702da40d5f1994",
      "31810c8cf2ac40529667d5fb4f098486",
      "0a6fe7ee8abf4570a7f60e9a6d596553",
      "87e0c1d18a174a8e9b64f4a36edde77b",
      "290b7bb6c8b14cc995744b7f230f219d",
      "95cb330fa0b84393a0d05792d52efc5e",
      "d7ce2b78ade74cc998902e82a15e598d",
      "5537f8da6b6c4e98b0f34be2bfc7f813",
      "6d340914dcb44b4bb2266406f1d8ee52",
      "e739fc5d0b754d248b7b1a2991d7827d",
      "86b6b078470842aea33430a428593feb",
      "97f636762a6a4af28350fa920afbde3a",
      "77bd027410d543139e711133155b6d8c",
      "be18c5da0a984805a338899ff99602fa",
      "d1d1eb1c9c484ea1a3e196f74177a62e",
      "f999044926ff451db18498e557f0ce83",
      "8a137facc0254f15a56b25cdad23d135",
      "1076a9ab2ea4449dbd4dc1e7eb371ab4",
      "0b327a5fe6f04c25b05972731e59540f",
      "ce72e85c9ddc4dbdb42080b84615d184",
      "8d2da01823ed44ccbf7bba68242e2352",
      "bcffbc5e564e4ac7b476823523b73d4e",
      "31b6c9c220c64c828d9bd168e725329c",
      "801bcfaa50f84201930ce847f947cb50"
     ]
    },
    "executionInfo": {
     "elapsed": 17214,
     "status": "ok",
     "timestamp": 1753476124990,
     "user": {
      "displayName": "Srishti Jain",
      "userId": "17735186882349502119"
     },
     "user_tz": 240
    },
    "id": "LHZK9YlMFTCX",
    "outputId": "cc06cc6d-ba40-428a-e778-cac2df9aae2b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f409523dfa724375898d702f6e01daec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02cdf6fd55a445f9b66cddbd92b3559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2937f86e111457cb2e11383edd6266e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ebc5f92f1140cebfba161f2d3f1ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6fe7ee8abf4570a7f60e9a6d596553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4459 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be18c5da0a984805a338899ff99602fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1115 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sms', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 4459\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Let's use a lambda function to tokenize all the examples\n",
    "tokenized_dataset = {}\n",
    "for split in splits:\n",
    "    tokenized_dataset[split] = dataset[split].map(\n",
    "        lambda x: tokenizer(x[\"sms\"], truncation=True), batched=True\n",
    "    )\n",
    "\n",
    "# Inspect the available columns in the dataset\n",
    "tokenized_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2O-Oe74FTCY"
   },
   "source": [
    "## Load and set up the model\n",
    "\n",
    "In this case we are doing a full fine tuning, so we will want to unfreeze all parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "referenced_widgets": [
      "2dfd76dc8b7e4ffe9f25a44106ec8045",
      "d5121610f8a04e3287ed4085e81703c7",
      "561da766cf774d5ea0c377004c718ae9",
      "dc8263cd4aea48f68e3f3fe3df55f152",
      "42b5005fcd09414f82f7f06a48f52913",
      "d5311152d26047e290d3936836bcd856",
      "36d023fdd73740d5b599bb371a704cbd",
      "697518e700e74715b42280f3430663ff",
      "6be1639d4df848538633f10092474c46",
      "a7efaf4f511c40f8ab712c0a1930ada2",
      "8c83fe3771a244c6b300fe2b0704a6fd"
     ]
    },
    "executionInfo": {
     "elapsed": 18316,
     "status": "ok",
     "timestamp": 1753476175276,
     "user": {
      "displayName": "Srishti Jain",
      "userId": "17735186882349502119"
     },
     "user_tz": 240
    },
    "id": "cpaamNuoFTCZ",
    "outputId": "4e92f9b4-01f8-4dbc-add5-3b0fcd59caee"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dfd76dc8b7e4ffe9f25a44106ec8045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=2,\n",
    "    id2label={0: \"not spam\", 1: \"spam\"},\n",
    "    label2id={\"not spam\": 0, \"spam\": 1},\n",
    ")\n",
    "\n",
    "# Unfreeze all the model parameters.\n",
    "# Tip: Check the documentation at https://huggingface.co/transformers/v4.2.2/training.html\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1753476188728,
     "user": {
      "displayName": "Srishti Jain",
      "userId": "17735186882349502119"
     },
     "user_tz": 240
    },
    "id": "tkQJdypGFTCZ",
    "outputId": "0e6084a2-8a28-4584-a1ce-bb43da336678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): DistilBertSdpaAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIZcyx2cFTCZ"
   },
   "source": [
    "## Let's train it!\n",
    "\n",
    "Now it's time to train our model. We'll use the `Trainer` class.\n",
    "\n",
    "First we'll define a function to compute our accuracy metreic then we make the `Trainer`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "executionInfo": {
     "elapsed": 3583323,
     "status": "ok",
     "timestamp": 1753479864639,
     "user": {
      "displayName": "Srishti Jain",
      "userId": "17735186882349502119"
     },
     "user_tz": 240
    },
    "id": "BQa9vdt5FTCZ",
    "outputId": "805588b9-26d5-42a5-b831-eff04ebcb795"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-8-1776732893.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='558' max='558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [558/558 59:32, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.050811</td>\n",
       "      <td>0.987444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.053000</td>\n",
       "      <td>0.056349</td>\n",
       "      <td>0.987444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=558, training_loss=0.051121345130346156, metrics={'train_runtime': 3582.105, 'train_samples_per_second': 2.49, 'train_steps_per_second': 0.156, 'total_flos': 144666559425588.0, 'train_loss': 0.051121345130346156, 'epoch': 2.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "\n",
    "# The HuggingFace Trainer class handles the training and eval loop for PyTorch for us.\n",
    "# Read more about it here https://huggingface.co/docs/transformers/main_classes/trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/spam_not_spam\",\n",
    "        # Set the learning rate\n",
    "        learning_rate=2e-5,\n",
    "        # Set the per device train batch size and eval batch size\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        # Evaluate and save the model after each epoch\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        # Set the learning rate\n",
    "        num_train_epochs=2,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=\"none\"\n",
    "    ),\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YklWuo-oFTCa"
   },
   "source": [
    "## Evaluate the model\n",
    "\n",
    "Evaluating the model is as simple as calling the evaluate method on the trainer object. This will run the model on the test set and compute the metrics we specified in the compute_metrics function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "executionInfo": {
     "elapsed": 130030,
     "status": "ok",
     "timestamp": 1753480050179,
     "user": {
      "displayName": "Srishti Jain",
      "userId": "17735186882349502119"
     },
     "user_tz": 240
    },
    "id": "cNnn4MDeFTCa",
    "outputId": "e74e18c4-4de5-41df-e74f-9efc3fff8f59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 02:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.050810907036066055,\n",
       " 'eval_accuracy': 0.9874439461883409,\n",
       " 'eval_runtime': 130.0196,\n",
       " 'eval_samples_per_second': 8.576,\n",
       " 'eval_steps_per_second': 0.538,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the performance of the model on the test set\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSzsqbQmFTCa"
   },
   "source": [
    "### View the results\n",
    "\n",
    "Let's look at a few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFVfwYkJFTCa",
    "outputId": "dca0a2cc-6b15-42b8-df49-a0ec9f8ced29"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "      <th>predictions</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yup... Hey then one day on fri we can ask miwa and jiayin take leave go karaoke \\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy new years melody!\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRIVATE! Your 2003 Account Statement for shows 800 un-redeemed S. I. M. points. Call 08715203652 Identifier Code: 42810 Expires 29/10/0\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>URGENT! We are trying to contact U. Todays draw shows that you have won a Â£800 prize GUARANTEED. Call 09050003091 from land line. Claim C52. Valid 12hrs only\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I had askd u a question some hours before. Its answer\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SMS. ac JSco: Energy is high, but u may not know where 2channel it. 2day ur leadership skills r strong. Psychic? Reply ANS w/question. End? Reply END JSCO\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Yun ah.the ubi one say if Ã¼ wan call by tomorrow.call 67441233 look for irene.ere only got bus8,22,65,61,66,382. Ubi cres,ubi tech park.6ph for 1st 5wkg days.Ã¨n\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Burger King - Wanna play footy at a top stadium? Get 2 Burger King before 1st Sept and go Large or Super with Coca-Cola and walk out a winner\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                  sms  \\\n",
       "0                                                                                  Yup... Hey then one day on fri we can ask miwa and jiayin take leave go karaoke \\n   \n",
       "1                                                                                                                                           Happy new years melody!\\n   \n",
       "2                           PRIVATE! Your 2003 Account Statement for shows 800 un-redeemed S. I. M. points. Call 08715203652 Identifier Code: 42810 Expires 29/10/0\\n   \n",
       "3     URGENT! We are trying to contact U. Todays draw shows that you have won a Â£800 prize GUARANTEED. Call 09050003091 from land line. Claim C52. Valid 12hrs only\\n   \n",
       "4                                                                                                             I had askd u a question some hours before. Its answer\\n   \n",
       "5        SMS. ac JSco: Energy is high, but u may not know where 2channel it. 2day ur leadership skills r strong. Psychic? Reply ANS w/question. End? Reply END JSCO\\n   \n",
       "6  Yun ah.the ubi one say if Ã¼ wan call by tomorrow.call 67441233 look for irene.ere only got bus8,22,65,61,66,382. Ubi cres,ubi tech park.6ph for 1st 5wkg days.Ã¨n\\n   \n",
       "7                     Burger King - Wanna play footy at a top stadium? Get 2 Burger King before 1st Sept and go Large or Super with Coca-Cola and walk out a winner\\n   \n",
       "\n",
       "   predictions  labels  \n",
       "0            0       0  \n",
       "1            0       0  \n",
       "2            1       1  \n",
       "3            1       1  \n",
       "4            0       0  \n",
       "5            0       1  \n",
       "6            0       0  \n",
       "7            0       1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a dataframe with the predictions and the text and the labels\n",
    "import pandas as pd\n",
    "\n",
    "items_for_manual_review = tokenized_dataset[\"test\"].select(\n",
    "    [0, 1, 22, 31, 43, 292, 448, 487]\n",
    ")\n",
    "\n",
    "results = trainer.predict(items_for_manual_review)\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"sms\": [item[\"sms\"] for item in items_for_manual_review],\n",
    "        \"predictions\": results.predictions.argmax(axis=1),\n",
    "        \"labels\": results.label_ids,\n",
    "    }\n",
    ")\n",
    "# Show all the cell\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMSuSii4krgP"
   },
   "outputs": [],
   "source": [
    "import nbformat\n",
    "\n",
    "path = \"cleaned_notebook.ipynb\"\n",
    "\n",
    "# Get the current notebook contents\n",
    "from google.colab import _message\n",
    "nb = _message.blocking_request('get_ipynb')['ipynb']\n",
    "\n",
    "# Remove 'widgets' metadata if present\n",
    "if 'widgets' in nb['metadata']:\n",
    "    del nb['metadata']['widgets']\n",
    "\n",
    "# Save the cleaned notebook\n",
    "with open(path, \"w\") as f:\n",
    "    nbformat.write(nbformat.from_dict(nb), f)\n",
    "\n",
    "print(f\"Cleaned notebook saved as {path}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
